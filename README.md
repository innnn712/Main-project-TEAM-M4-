
# 야간 오토바이 주행 데이터셋 분석 정리

## 1. 이미지 파일 구조
```
kaggleData01/
└── www.acmeai.tech ODataset 1 - Motorcycle Night Ride Dataset/
    ├── COCO_motorcycle (pixel).json     ← 어노테이션 (COCO 포맷)
    ├── PDF (데이터셋 설명서)
    └── images/ (총 600개 파일 = 200 × 3종)
        ├── night ride (7~100).png         ← 원본 93장 (매우 어두움, 평균밝기 24.6)
        ├── Screenshot (309~450).png       ← 원본 107장 (약간 밝음, 평균밝기 61.6)
        ├── *___fuse.png                   ← 세그멘테이션 마스크 (학습용!)
        └── *___save.png                   ← 원본+마스크 오버레이 (확인용)
```

**핵심 포인트**: night ride 시리즈는 극도로 어두운 장면(평균밝기 24.6/255)이고, Screenshot 시리즈는 상대적으로 밝은 장면(61.6/255)입니다. 같은 야간 데이터지만 밝기 편차가 큽니다.

---

## 2. Fuse 마스크 색상-클래스 매핑

| 색상 (RGB) | 시각 색상 | 클래스 | 의미 |
|-----------|----------|--------|------|
| (245, 166, 35) | 주황 | Undrivable | 비주행영역 (하늘, 건물 등) |
| (155, 155, 155) | 회색 | Road | 주행 가능 도로 |
| (74, 144, 226) | 파랑 | My bike | 내 오토바이 부분 |
| (65, 117, 6) | 진녹 | Rider | 라이더(나) |
| (248, 231, 28) | 노랑 | Lane Mark | 차선 표시 |
| (57, 234, 92) | 연두 | Moveable | 이동물체(차량, 보행자) |
| (0, 0, 0) | 검정 | Background | 미분류 영역 |

---

## 3. COCO JSON 요약

### 기본 정보

| 항목 | 내용 |
|------|------|
| 총 이미지 | 200장 (모두 1920×1080) |
| 총 어노테이션 | 2,305개 |
| 클래스 수 | 6개 |
| 어노테이션 형식 | COCO Polygon (픽셀 단위 폴리곤 좌표) |
| 이미지당 어노테이션 | 5~26개 (평균 11.5개) |
| 생성 도구 | SuperAnnotate AI |

### 클래스별 핵심 통계

| 클래스 | 개수 | 평균 면적% | 특이사항 |
|--------|------|-----------|---------|
| Moveable | 1,298 | 0.73% | 개수는 많지만 면적 극소 (원거리 차량) |
| Lane Mark | 207 | 1.39% | 일부 이미지에 없음 (3장) |
| Undrivable | 200 | 42.89% | 최대 면적, 항상 존재 |
| Road | 200 | 27.11% | 두 번째로 큰 면적 |
| My bike | 200 | 15.80% | 항상 존재 (1인칭 시점) |
| Rider | 200 | 8.06% | 항상 존재 |

---

## 4. 데이터셋의 핵심 도전과제

이 프로젝트에서 해결해야 할 주요 문제들입니다.

1. **극심한 클래스 불균형**: Undrivable(43%) vs Moveable(0.73%)로 62배 차이가 있습니다.
2. **소규모 데이터**: 200장만 있어서 과적합 위험이 매우 높습니다.
3. **야간 저조도**: 평균 밝기가 44/255로 낮아서 피처 추출이 어렵습니다.
4. **밝기 편차**: night ride(25) vs Screenshot(62)로 데이터 내 편차가 존재합니다.
5. **소형 객체**: Moveable 중앙값 면적이 0.08%로 거의 점 수준입니다.

---

## 5. 프로젝트 제안

### 추천 프로젝트 주제
"야간 오토바이 주행 장면 Semantic Segmentation — 체계적 모델 비교 및 성능 최적화"

### 이 방향을 추천하는 이유

- 평가기준의 "여러 가지 시도"와 "논리적 접근"을 모두 만족할 수 있습니다
- 모델 비교 + Loss 함수 실험 + 전처리 실험으로 충분한 실험 볼륨을 확보할 수 있습니다
- Kaggle/Colab T4 GPU 환경에서 충분히 수행 가능합니다

### 제안 단계

| 단계 | 내용 | 기대 시간 |
|------|------|----------|
| 1. EDA | 위 분석 + 시각화 (밝기 히스토그램, 클래스 분포, 샘플 시각화) | 0.5일 |
| 2. 전처리 | COCO→마스크 변환, train/val 분할, augmentation 파이프라인 | 1일 |
| 3. Baseline | U-Net + ResNet34 backbone (가장 기본) | 1일 |
| 4. 모델 비교 | DeepLabV3+ / SegFormer 추가 비교 | 1~2일 |
| 5. 성능 향상 | Loss 함수(Dice+Focal), 이미지 Enhancement(CLAHE), TTA | 1~2일 |
| 6. 분석/발표 | 클래스별 IoU 분석, 실패 케이스, 결론 | 1일 |



### EDA review 

#### 1: 환경 설정 & 데이터 로드

  - 필요한 라이브러리 import (numpy, pandas, matplotlib, seaborn, PIL 등)
  - 데이터 경로 설정 (이미지 폴더, COCO JSON 파일)

#### 2: COCO JSON 파싱

  - COCO 포맷의 어노테이션 파일을 로드
  - 200장 이미지, 2305개 어노테이션, 6개 카테고리 확인
  - ID → 이름 매핑 딕셔너리 생성

#### 3: 기본 통계 분석

  - 클래스별 어노테이션 개수/비율 계산
  - 막대그래프 + 파이차트로 클래스 분포 시각화
  - 클래스 불균형 확인 (Moveable이 56.3%로 과다)

#### 4: 야간 이미지 특성 분석

  - 30장 샘플 이미지의 밝기, 대비, RGB 채널 평균 계산
  - 4개 차트로 시각화:
    - 밝기 분포 히스토그램
    - 대비 분포 히스토그램
    - RGB 채널별 박스플롯
    - 밝기 vs 대비 산점도
  - 야간 이미지 특성: 평균 밝기 ~95, 저조도 환경 확인

#### 5: 세그멘테이션 복잡도 분석

  - 각 어노테이션의 폴리곤 꼭짓점 수로 복잡도 분류
    - Simple (≤8), Moderate (9~20), Complex (>20)
  - 클래스별 복잡도 크로스탭 + 히트맵 시각화
  - 대부분 Complex(복잡한 경계선)임을 확인

#### 6: 객체 크기 & 위치 분석

  - 객체 면적을 이미지 대비 상대적 크기로 분류 (Small/Medium/Large)
  - 4개 차트:
    - 크기 카테고리별 분포
    - 클래스별 상대 크기 박스플롯
    - 면적 히스토그램
    - bbox 중심점 산점도 (객체 위치 분포)

#### 7: 모델링 인사이트

  - 데이터셋 특성 요약 (클래스 불균형 6.49배)
  - 모델링 추천: U-Net++/DeepLabv3+, Focal+Dice Loss, CLAHE 전처리 등
  - 데이터 품질 평가 종합 점수: ?/100

  ---
  인사이트: 야간 저조도 + 클래스 불균형이 심해서, Focal Loss와 밝기 보정 전처리가 필수적 .....


### 용어 집어 보기 
#### Baseline = 기준점 (모델 :U-Net + ResNet34 ,Loss :CE + Dice,결과 Val mIoU ~0.59 이것을 기준으로 다른 실험과 비교)
#### 특징 추출 (이미지 -> 압축) : Encoder = Backbone 이번 학습 예시 : ResNet34
#### 복원 (압축->픽셀별 예측)  : Decoder = Head 이번 학습 예시 : U-Net 디코더 
정리하면, "U-Net + ResNet34"라고 할 때:
  - ResNet34 → Encoder(백본) - 갈아끼울 수 있음 (EfficientNet, VGG 등)
  - U-Net → 전체 Encoder-Decoder 구조를 정의하는 아키텍처
#### Annotation :이지미에 대한 정답 표시 (라벨링) 모델은 이 어노데이션을 정답(Ground Truth)으로 사용해서학습 
#### mIOU (mean intersection over union) 세그멘테이션 측정 지표 ,하나의 클래스에 전체 합친부분의 겹치는 부분 즉  모든 클래스으 IoU를 평균낸값


### CLAHE 적응형 히스토그램 균등화 기법의 야간 차선 detection 적용 
clipLimit=2.0, tileGridSize=(8,8)은 OpenCV 기본값이자 안전한 출발점이지만, 야간 차선 검출에 반드시 최적은 아닙니다.
파라미터별 고려사항
1. clipLimit (대비 강도)
값: 2.0
야간 차선에 대한 효과: 안정적이지만 보수적. 매우 어두운 구간에서 차선이 여전히 약할 수 있음
값: 3.0~4.0
야간 차선에 대한 효과: 야간 이미지에서는 이 범위가 더 효과적일 수 있음. 어두운 도로의 차선 대비가 확실히 올라감
값: 8.0+
야간 차선에 대한 효과: 노이즈 증폭이 심해서 비권장
2. tileGridSize (타일 크기)
값: (4,4)
특성: 더 지역적으로 균등화. 좁은 영역의 차선에 민감하지만 아티팩트 위험
값: (8,8)
특성: 범용적으로 무난. 대부분의 경우 잘 동작
값: (16,16)
특성: 넓은 영역 단위. 전역 균등화에 가까워짐
권장사항
야간 차선 검출 목적이라면 clipLimit을 3.0~4.0으로 올려서 테스트해보는 것을 추천합니다. tileGridSize=(8,8)은 그대로 유지해도 됩니다.
테스트해볼 조합:
apply_clahe(image, clip_limit=3.0, tile_grid_size=(8, 8))  # 추천 1순위
apply_clahe(image, clip_limit=4.0, tile_grid_size=(8, 8))  # 추천 2순위
clipLimit 비교 셀(4-3)을 실행해서 실제 이미지에서 차선이 가장 뚜렷하게 보이는 값을 눈으로 확인하고 결정하는 것이 가장 정확합니다.



